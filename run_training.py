#!/usr/bin/env python3
"""
ä¸»è®­ç»ƒè„šæœ¬ - æ”¯æŒå¤šç§è®­ç»ƒæ¨¡å¼å’Œé…ç½®é€‰é¡¹
"""

import os
import sys
import argparse
import logging
from typing import Optional, List, Dict

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, project_root)

from config import config, LoggingConfig
from trainer import SFTTrainer, quick_train, train_with_config
from data_manager import list_available_datasets, create_dataset
from evaluation import ModelEvaluator

def setup_logging_from_config():
    """ä»é…ç½®è®¾ç½®æ—¥å¿—"""
    try:
        # è®¾ç½®æ—¥å¿—é…ç½®
        logger = config.logging.setup()
        logger.info("ğŸš€ æ—¥å¿—ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
        return logger
    except Exception as e:
        print(f"âŒ æ—¥å¿—è®¾ç½®å¤±è´¥: {e}")
        # ä½¿ç”¨åŸºæœ¬æ—¥å¿—é…ç½®
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        return logging.getLogger(__name__)

# åˆå§‹åŒ–æ—¥å¿—
logger = setup_logging_from_config()

def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    logger.info("ğŸ“‹ è§£æå‘½ä»¤è¡Œå‚æ•°...")
    
    parser = argparse.ArgumentParser(
        description="SFT è®­ç»ƒè„šæœ¬ - æ”¯æŒå¤šç§è®­ç»ƒæ¨¡å¼",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # å¿«é€Ÿè®­ç»ƒ
  python run_training.py --mode quick --model qwen_7b --datasets english_adult chinese_shy
  
  # è‡ªå®šä¹‰è®­ç»ƒ
  python run_training.py --mode custom --epochs 5 --batch-size 8
  
  # åˆ—å‡ºå¯ç”¨æ•°æ®é›†
  python run_training.py --mode list-data
  
  # è¯„ä¼°æ¨¡å‹
  python run_training.py --mode evaluate --model-path ./models/sft_output
        """
    )
    
    # åŸºæœ¬å‚æ•°
    parser.add_argument(
        "--mode", 
        choices=["quick", "custom", "full", "list-data", "evaluate", "demo"],
        default="demo",
        help="è®­ç»ƒæ¨¡å¼ (é»˜è®¤: demo)"
    )
    
    parser.add_argument(
        "--model", 
        type=str,
        help="æ¨¡å‹é”®å (å¦‚: qwen_7b, llama3_8b)"
    )
    
    parser.add_argument(
        "--datasets", 
        nargs="+",
        help="æ•°æ®é›†åˆ—è¡¨ (å¦‚: english_adult chinese_shy)"
    )
    
    # è®­ç»ƒå‚æ•°
    parser.add_argument(
        "--epochs", 
        type=int, 
        default=3,
        help="è®­ç»ƒè½®æ•° (é»˜è®¤: 3)"
    )
    
    parser.add_argument(
        "--batch-size", 
        type=int, 
        default=4,
        help="æ‰¹æ¬¡å¤§å° (é»˜è®¤: 4)"
    )
    
    parser.add_argument(
        "--learning-rate", 
        type=float, 
        default=2e-5,
        help="å­¦ä¹ ç‡ (é»˜è®¤: 2e-5)"
    )
    
    parser.add_argument(
        "--max-length", 
        type=int, 
        default=512,
        help="æœ€å¤§åºåˆ—é•¿åº¦ (é»˜è®¤: 512)"
    )
    
    # è¾“å‡ºå’Œæ—¥å¿—
    parser.add_argument(
        "--output-dir", 
        type=str,
        help="è¾“å‡ºç›®å½• (é»˜è®¤ä½¿ç”¨é…ç½®æ–‡ä»¶è®¾ç½®)"
    )
    
    parser.add_argument(
        "--log-level", 
        choices=["DEBUG", "INFO", "WARNING", "ERROR"],
        default="INFO",
        help="æ—¥å¿—çº§åˆ« (é»˜è®¤: INFO)"
    )
    
    parser.add_argument(
        "--log-file", 
        type=str,
        help="æ—¥å¿—æ–‡ä»¶è·¯å¾„"
    )
    
    # è¯„ä¼°å‚æ•°
    parser.add_argument(
        "--model-path", 
        type=str,
        help="è¯„ä¼°æ¨¡å‹è·¯å¾„"
    )
    
    # å…¶ä»–é€‰é¡¹
    parser.add_argument(
        "--dry-run", 
        action="store_true",
        help="ä»…æ˜¾ç¤ºé…ç½®ï¼Œä¸æ‰§è¡Œè®­ç»ƒ"
    )
    
    parser.add_argument(
        "--verbose", 
        action="store_true",
        help="æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯"
    )
    
    args = parser.parse_args()
    
    logger.info(f"âœ… è§£æå®Œæˆï¼Œæ¨¡å¼: {args.mode}")
    if args.verbose:
        logger.info(f"ğŸ“‹ å‘½ä»¤è¡Œå‚æ•°: {vars(args)}")
    
    return args

def update_config_from_args(args):
    """æ ¹æ®å‘½ä»¤è¡Œå‚æ•°æ›´æ–°é…ç½®"""
    global logger
    logger.info("ğŸ”§ æ ¹æ®å‘½ä»¤è¡Œå‚æ•°æ›´æ–°é…ç½®...")
    
    try:
        # æ›´æ–°æ—¥å¿—é…ç½®
        if args.log_level:
            config.logging.log_level = args.log_level
        if args.log_file:
            config.logging.log_file = args.log_file
        
        # é‡æ–°è®¾ç½®æ—¥å¿—
        if args.log_level or args.log_file:
            logger = config.logging.setup()
            logger.info("ğŸ”„ æ—¥å¿—é…ç½®å·²æ›´æ–°")
        
        # æ›´æ–°æ¨¡å‹é…ç½®
        if args.model:
            config.update_model(args.model)
            logger.info(f"ğŸ¤– æ¨¡å‹å·²è®¾ç½®ä¸º: {args.model}")
        
        # æ›´æ–°æ•°æ®é…ç½®
        if args.datasets:
            config.update_datasets(args.datasets)
            logger.info(f"ğŸ“Š æ•°æ®é›†å·²è®¾ç½®ä¸º: {args.datasets}")
        
        # æ›´æ–°è®­ç»ƒé…ç½®
        if args.epochs:
            config.training.num_train_epochs = args.epochs
            logger.info(f"ğŸ”„ è®­ç»ƒè½®æ•°: {args.epochs}")
        
        if args.batch_size:
            config.training.per_device_train_batch_size = args.batch_size
            logger.info(f"ğŸ“¦ æ‰¹æ¬¡å¤§å°: {args.batch_size}")
        
        if args.learning_rate:
            config.training.learning_rate = args.learning_rate
            logger.info(f"ğŸ“ˆ å­¦ä¹ ç‡: {args.learning_rate}")
        
        if args.output_dir:
            config.training.output_dir = args.output_dir
            logger.info(f"ğŸ“ è¾“å‡ºç›®å½•: {args.output_dir}")
        
        # æ›´æ–°æ•°æ®é…ç½®
        if args.max_length:
            config.data.max_length = args.max_length
            logger.info(f"ğŸ“ æœ€å¤§é•¿åº¦: {args.max_length}")
        
        logger.info("âœ… é…ç½®æ›´æ–°å®Œæˆ")
        
    except Exception as e:
        logger.error(f"âŒ é…ç½®æ›´æ–°å¤±è´¥: {str(e)}", exc_info=True)
        raise

def show_current_config():
    """æ˜¾ç¤ºå½“å‰é…ç½®"""
    logger.info("ğŸ“‹ å½“å‰é…ç½®ä¿¡æ¯:")
    
    try:
        # æ¨¡å‹é…ç½®
        model_info = config.get_model_info()
        logger.info("ğŸ¤– æ¨¡å‹é…ç½®:")
        logger.info(f"   æ¨¡å‹åç§°: {model_info['model_name']}")
        logger.info(f"   æ•°æ®ç±»å‹: {model_info['load_config']['torch_dtype']}")
        logger.info(f"   8ä½é‡åŒ–: {model_info['load_config']['load_in_8bit']}")
        logger.info(f"   LoRA r: {model_info['lora_config']['r']}")
        logger.info(f"   LoRA alpha: {model_info['lora_config']['alpha']}")
        
        # æ•°æ®é…ç½®
        data_info = config.get_data_info()
        logger.info("ğŸ“Š æ•°æ®é…ç½®:")
        logger.info(f"   æ´»è·ƒæ•°æ®é›†: {data_info['active_datasets']}")
        logger.info(f"   æœ€å¤§é•¿åº¦: {data_info['max_length']}")
        logger.info(f"   è¾“å‡ºæ–‡ä»¶: {data_info['output_file']}")
        
        # è®­ç»ƒé…ç½®
        logger.info("âš™ï¸  è®­ç»ƒé…ç½®:")
        logger.info(f"   è®­ç»ƒè½®æ•°: {config.training.num_train_epochs}")
        logger.info(f"   æ‰¹æ¬¡å¤§å°: {config.training.per_device_train_batch_size}")
        logger.info(f"   å­¦ä¹ ç‡: {config.training.learning_rate}")
        logger.info(f"   è¾“å‡ºç›®å½•: {config.training.output_dir}")
        
    except Exception as e:
        logger.error(f"âŒ æ˜¾ç¤ºé…ç½®å¤±è´¥: {str(e)}")

def mode_quick_train(args):
    """å¿«é€Ÿè®­ç»ƒæ¨¡å¼"""
    logger.info("ğŸš€ å¯åŠ¨å¿«é€Ÿè®­ç»ƒæ¨¡å¼...")
    
    try:
        if args.dry_run:
            logger.info("ğŸ” å¹²è¿è¡Œæ¨¡å¼ - ä»…æ˜¾ç¤ºé…ç½®")
            show_current_config()
            return True
        
        # æ‰§è¡Œå¿«é€Ÿè®­ç»ƒ
        result = quick_train(
            model_key=args.model,
            datasets=args.datasets,
            epochs=args.epochs,
            batch_size=args.batch_size
        )
        
        if result:
            logger.info(f"ğŸ‰ å¿«é€Ÿè®­ç»ƒæˆåŠŸå®Œæˆ! æ¨¡å‹ä¿å­˜åœ¨: {result}")
            return True
        else:
            logger.error("âŒ å¿«é€Ÿè®­ç»ƒå¤±è´¥")
            return False
            
    except Exception as e:
        logger.error(f"âŒ å¿«é€Ÿè®­ç»ƒå¼‚å¸¸: {str(e)}", exc_info=True)
        return False

def mode_custom_train(args):
    """è‡ªå®šä¹‰è®­ç»ƒæ¨¡å¼"""
    logger.info("ğŸ”§ å¯åŠ¨è‡ªå®šä¹‰è®­ç»ƒæ¨¡å¼...")
    
    try:
        if args.dry_run:
            logger.info("ğŸ” å¹²è¿è¡Œæ¨¡å¼ - ä»…æ˜¾ç¤ºé…ç½®")
            show_current_config()
            return True
        
        # æ„å»ºé…ç½®æ›´æ–°
        config_updates = {}
        
        if args.epochs or args.batch_size or args.learning_rate or args.output_dir:
            config_updates["training"] = {}
            if args.epochs:
                config_updates["training"]["num_train_epochs"] = args.epochs
            if args.batch_size:
                config_updates["training"]["per_device_train_batch_size"] = args.batch_size
            if args.learning_rate:
                config_updates["training"]["learning_rate"] = args.learning_rate
            if args.output_dir:
                config_updates["training"]["output_dir"] = args.output_dir
        
        if args.max_length:
            config_updates["data"] = {"max_length": args.max_length}
        
        # æ‰§è¡Œè‡ªå®šä¹‰è®­ç»ƒ
        result = train_with_config(config_updates)
        
        if result:
            logger.info(f"ğŸ‰ è‡ªå®šä¹‰è®­ç»ƒæˆåŠŸå®Œæˆ! æ¨¡å‹ä¿å­˜åœ¨: {result}")
            return True
        else:
            logger.error("âŒ è‡ªå®šä¹‰è®­ç»ƒå¤±è´¥")
            return False
            
    except Exception as e:
        logger.error(f"âŒ è‡ªå®šä¹‰è®­ç»ƒå¼‚å¸¸: {str(e)}", exc_info=True)
        return False

def mode_full_train(args):
    """å®Œæ•´è®­ç»ƒæ¨¡å¼"""
    logger.info("ğŸ¯ å¯åŠ¨å®Œæ•´è®­ç»ƒæ¨¡å¼...")
    
    try:
        if args.dry_run:
            logger.info("ğŸ” å¹²è¿è¡Œæ¨¡å¼ - ä»…æ˜¾ç¤ºé…ç½®")
            show_current_config()
            return True
        
        # åˆ›å»ºè®­ç»ƒå™¨
        trainer = SFTTrainer(
            model_config=config.model,
            training_config=config.training,
            data_config=config.data
        )
        
        # è¿è¡Œå®Œæ•´è®­ç»ƒæµç¨‹
        result = trainer.run_full_training()
        
        if result:
            logger.info("ğŸ‰ å®Œæ•´è®­ç»ƒæˆåŠŸå®Œæˆ!")
            return True
        else:
            logger.error("âŒ å®Œæ•´è®­ç»ƒå¤±è´¥")
            return False
            
    except Exception as e:
        logger.error(f"âŒ å®Œæ•´è®­ç»ƒå¼‚å¸¸: {str(e)}", exc_info=True)
        return False

def mode_list_data(args):
    """åˆ—å‡ºæ•°æ®é›†æ¨¡å¼"""
    logger.info("ğŸ“‹ åˆ—å‡ºå¯ç”¨æ•°æ®é›†...")
    
    try:
        list_available_datasets()
        logger.info("âœ… æ•°æ®é›†åˆ—è¡¨æ˜¾ç¤ºå®Œæˆ")
        return True
        
    except Exception as e:
        logger.error(f"âŒ åˆ—å‡ºæ•°æ®é›†å¤±è´¥: {str(e)}", exc_info=True)
        return False

def mode_evaluate(args):
    """è¯„ä¼°æ¨¡å¼"""
    logger.info("ğŸ“Š å¯åŠ¨è¯„ä¼°æ¨¡å¼...")
    
    try:
        model_path = args.model_path or config.training.output_dir
        
        if not model_path or not os.path.exists(model_path):
            logger.error(f"âŒ æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {model_path}")
            return False
        
        logger.info(f"ğŸ” è¯„ä¼°æ¨¡å‹: {model_path}")
        
        evaluator = ModelEvaluator()
        results = evaluator.evaluate_model(model_path)
        
        logger.info("ğŸ“Š è¯„ä¼°ç»“æœ:")
        for metric, value in results.items():
            logger.info(f"   {metric}: {value}")
        
        logger.info("âœ… è¯„ä¼°å®Œæˆ")
        return True
        
    except Exception as e:
        logger.error(f"âŒ è¯„ä¼°å¤±è´¥: {str(e)}", exc_info=True)
        return False

def mode_demo(args):
    """æ¼”ç¤ºæ¨¡å¼"""
    logger.info("ğŸª å¯åŠ¨æ¼”ç¤ºæ¨¡å¼...")
    
    print("\n" + "="*60)
    print("ğŸ¯ SFT è®­ç»ƒç³»ç»Ÿæ¼”ç¤º")
    print("="*60)
    
    # æ˜¾ç¤ºå½“å‰é…ç½®
    print("\nğŸ“‹ å½“å‰é…ç½®:")
    show_current_config()
    
    # æ˜¾ç¤ºå¯ç”¨æ•°æ®é›†
    print("\nğŸ“Š å¯ç”¨æ•°æ®é›†:")
    list_available_datasets()
    
    # æ˜¾ç¤ºä½¿ç”¨ç¤ºä¾‹
    print("\nğŸ’¡ ä½¿ç”¨ç¤ºä¾‹:")
    print("1. å¿«é€Ÿè®­ç»ƒ:")
    print("   python run_training.py --mode quick --model qwen_7b --datasets english_adult")
    
    print("\n2. è‡ªå®šä¹‰è®­ç»ƒ:")
    print("   python run_training.py --mode custom --epochs 5 --batch-size 8")
    
    print("\n3. å®Œæ•´è®­ç»ƒ:")
    print("   python run_training.py --mode full")
    
    print("\n4. è¯„ä¼°æ¨¡å‹:")
    print("   python run_training.py --mode evaluate --model-path ./models/sft_output")
    
    print("\n" + "="*60)
    
    logger.info("âœ… æ¼”ç¤ºå®Œæˆ")
    return True

def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸš€ å¯åŠ¨ SFT è®­ç»ƒç³»ç»Ÿ...")
    
    try:
        # è§£æå‘½ä»¤è¡Œå‚æ•°
        args = parse_arguments()
        
        # æ›´æ–°é…ç½®
        update_config_from_args(args)
        
        # æ ¹æ®æ¨¡å¼æ‰§è¡Œç›¸åº”æ“ä½œ
        success = False
        
        if args.mode == "quick":
            success = mode_quick_train(args)
        elif args.mode == "custom":
            success = mode_custom_train(args)
        elif args.mode == "full":
            success = mode_full_train(args)
        elif args.mode == "list-data":
            success = mode_list_data(args)
        elif args.mode == "evaluate":
            success = mode_evaluate(args)
        elif args.mode == "demo":
            success = mode_demo(args)
        else:
            logger.error(f"âŒ æœªçŸ¥æ¨¡å¼: {args.mode}")
            success = False
        
        # è¿”å›ç»“æœ
        if success:
            logger.info("ğŸ‰ ä»»åŠ¡æ‰§è¡ŒæˆåŠŸ!")
            sys.exit(0)
        else:
            logger.error("âŒ ä»»åŠ¡æ‰§è¡Œå¤±è´¥!")
            sys.exit(1)
            
    except KeyboardInterrupt:
        logger.warning("âš ï¸  ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        sys.exit(130)
    except Exception as e:
        logger.error(f"âŒ ç³»ç»Ÿå¼‚å¸¸: {str(e)}", exc_info=True)
        sys.exit(1)

if __name__ == "__main__":
    main() 