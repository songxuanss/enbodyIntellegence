# SFTè®­ç»ƒé…ç½®å’Œå¯åŠ¨è„šæœ¬

import json
import os
from datetime import datetime

# training dataset
from sft_adult_doll_eng import all_conversations

# 1. ä¿å­˜è®­ç»ƒæ•°æ®ä¸ºJSONæ–‡ä»¶
def save_training_data():
    """ä¿å­˜1000æ¡è®­ç»ƒæ•°æ®åˆ°JSONæ–‡ä»¶"""
    
    # è¿™é‡Œæ˜¯å®Œæ•´çš„1000æ¡è®­ç»ƒæ•°æ®
    training_data = [
        {
            "id": f"intimate_conversation_{i+1:04d}",
            "conversations": [
                {
                    "from": "human", 
                    "value": conversation["input"]
                },
                {
                    "from": "gpt",
                    "value": conversation["output"]
                }
            ]
        }
        for i, conversation in enumerate(all_conversations)  # ä½¿ç”¨ä¹‹å‰ç”Ÿæˆçš„1000æ¡æ•°æ®
    ]
    
    # ä¿å­˜åˆ°æ–‡ä»¶
    with open('intimate_sft_dataset.json', 'w', encoding='utf-8') as f:
        json.dump(training_data, f, indent=2, ensure_ascii=False)
    
    print(f"âœ… è®­ç»ƒæ•°æ®å·²ä¿å­˜åˆ° intimate_sft_dataset.json")
    print(f"ğŸ“Š æ€»æ ·æœ¬æ•°: {len(training_data)}")
    return 'intimate_sft_dataset.json'

# 2. SFTè®­ç»ƒé…ç½®
sft_config = {
    "model_name_or_path": "meta-llama/Llama-2-7b-chat-hf",  # åŸºç¡€æ¨¡å‹
    "data_path": "intimate_sft_dataset.json",  # è®­ç»ƒæ•°æ®è·¯å¾„
    "output_dir": "./intimate-model-sft",  # è¾“å‡ºç›®å½•
    "num_train_epochs": 3,  # è®­ç»ƒè½®æ•°
    "per_device_train_batch_size": 4,  # æ‰¹æ¬¡å¤§å°
    "per_device_eval_batch_size": 4,
    "gradient_accumulation_steps": 4,  # æ¢¯åº¦ç´¯ç§¯
    "learning_rate": 2e-5,  # å­¦ä¹ ç‡
    "max_seq_length": 512,  # æœ€å¤§åºåˆ—é•¿åº¦
    "logging_steps": 10,  # æ—¥å¿—è®°å½•é—´éš”
    "save_steps": 100,  # ä¿å­˜é—´éš”
    "eval_steps": 100,  # è¯„ä¼°é—´éš”
    "warmup_steps": 100,  # é¢„çƒ­æ­¥æ•°
    "save_total_limit": 3,  # ä¿å­˜æ£€æŸ¥ç‚¹æ•°é‡é™åˆ¶
    "load_best_model_at_end": True,
    "evaluation_strategy": "steps",
    "save_strategy": "steps",
    "report_to": "tensorboard",  # ä½¿ç”¨tensorboardè®°å½•
    "remove_unused_columns": False,
    "dataloader_pin_memory": False,
}

# 3. ä½¿ç”¨LLaMA-Factoryè¿›è¡ŒSFTè®­ç»ƒçš„é…ç½®
llamafactory_config = {
    "stage": "sft",
    "model_name": "llama2_7b_chat",
    "dataset": "intimate_dataset",
    "template": "llama2",
    "finetuning_type": "lora",  # ä½¿ç”¨LoRAè¿›è¡Œé«˜æ•ˆå¾®è°ƒ
    "lora_target": "q_proj,v_proj",
    "output_dir": "intimate_llama2_lora",
    "overwrite_cache": True,
    "per_device_train_batch_size": 2,
    "gradient_accumulation_steps": 4,
    "lr_scheduler_type": "cosine",
    "logging_steps": 10,
    "save_steps": 500,
    "learning_rate": 5e-5,
    "num_train_epochs": 3.0,
    "max_samples": 1000,
    "max_grad_norm": 1.0,
    "quantization_bit": 4,  # 4-bité‡åŒ–
    "loraplus_lr_ratio": 16.0,
    "use_unsloth": True,  # ä½¿ç”¨UnslothåŠ é€Ÿ
}

# 4. ç”Ÿæˆè®­ç»ƒè„šæœ¬
def generate_training_script():
    """ç”ŸæˆSFTè®­ç»ƒè„šæœ¬"""
    
    script_content = f'''#!/bin/bash

# SFTè®­ç»ƒè„šæœ¬ - äº²å¯†å¯¹è¯æ¨¡å‹
# ç”Ÿæˆæ—¶é—´: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}

echo "ğŸš€ å¼€å§‹SFTè®­ç»ƒ..."
echo "ğŸ“Š è®­ç»ƒæ•°æ®: intimate_sft_dataset.json (1000æ¡æ ·æœ¬)"
echo "ğŸ¤– åŸºç¡€æ¨¡å‹: Llama-2-7b-chat"

# æ–¹æ³•1: ä½¿ç”¨Transformersç›´æ¥è®­ç»ƒ
python -m torch.distributed.launch \\
    --nproc_per_node=1 \\
    --master_port=29500 \\
    train_sft.py \\
    --model_name_or_path meta-llama/Llama-2-7b-chat-hf \\
    --data_path intimate_sft_dataset.json \\
    --bf16 True \\
    --output_dir ./intimate-model-sft \\
    --num_train_epochs 3 \\
    --per_device_train_batch_size 4 \\
    --per_device_eval_batch_size 4 \\
    --gradient_accumulation_steps 4 \\
    --evaluation_strategy "steps" \\
    --eval_steps 100 \\
    --save_strategy "steps" \\
    --save_steps 100 \\
    --save_total_limit 3 \\
    --learning_rate 2e-5 \\
    --weight_decay 0.1 \\
    --warmup_steps 100 \\
    --lr_scheduler_type "cosine" \\
    --logging_steps 10 \\
    --report_to "tensorboard" \\
    --gradient_checkpointing True \\
    --deepspeed ds_config_zero2.json

echo "âœ… è®­ç»ƒå®Œæˆ!"

# æ–¹æ³•2: ä½¿ç”¨LLaMA-Factoryè®­ç»ƒ (æ¨è)
echo "ğŸ”„ æˆ–è€…ä½¿ç”¨LLaMA-Factoryè¿›è¡Œè®­ç»ƒ:"
echo "llamafactory-cli train examples/train_lora/llama2_lora_sft.yaml"

# æ–¹æ³•3: ä½¿ç”¨UnslothåŠ é€Ÿè®­ç»ƒ
echo "âš¡ æˆ–è€…ä½¿ç”¨UnslothåŠ é€Ÿè®­ç»ƒ:"
echo "python train_unsloth.py"
'''
    
    with open('train_intimate_sft.sh', 'w', encoding='utf-8') as f:
        f.write(script_content)
    
    os.chmod('train_intimate_sft.sh', 0o755)  # æ·»åŠ æ‰§è¡Œæƒé™
    print("âœ… è®­ç»ƒè„šæœ¬å·²ç”Ÿæˆ: train_intimate_sft.sh")

# 5. ç”ŸæˆPythonè®­ç»ƒè„šæœ¬
def generate_python_training_script():
    """ç”ŸæˆPythonè®­ç»ƒè„šæœ¬"""
    
    python_script = '''
import json
import torch
from transformers import (
    AutoTokenizer, 
    AutoModelForCausalLM,
    TrainingArguments,
    Trainer,
    DataCollatorForSeq2Seq
)
from datasets import Dataset
from peft import LoraConfig, get_peft_model, TaskType
import os

def load_dataset(file_path):
    """åŠ è½½è®­ç»ƒæ•°æ®"""
    with open(file_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    # è½¬æ¢ä¸ºè®­ç»ƒæ ¼å¼
    formatted_data = []
    for item in data:
        conversations = item['conversations']
        human_text = conversations[0]['value']
        gpt_text = conversations[1]['value']
        
        # æ ¼å¼åŒ–ä¸ºæŒ‡ä»¤æ ¼å¼
        formatted_text = f"Human: {human_text}\\nAssistant: {gpt_text}"
        formatted_data.append({"text": formatted_text})
    
    return Dataset.from_list(formatted_data)

def tokenize_function(examples, tokenizer, max_length=512):
    """æ•°æ®é¢„å¤„ç†"""
    return tokenizer(
        examples["text"],
        truncation=True,
        padding="max_length",
        max_length=max_length,
        return_tensors="pt"
    )

def main():
    # é…ç½®
    model_name = "meta-llama/Llama-2-7b-chat-hf"
    dataset_path = "intimate_sft_dataset.json"
    output_dir = "./intimate-model-sft"
    
    # åŠ è½½tokenizerå’Œæ¨¡å‹
    print("ğŸ”„ åŠ è½½æ¨¡å‹å’Œtokenizer...")
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    tokenizer.pad_token = tokenizer.eos_token
    
    model = AutoModelForCausalLM.from_pretrained(
        model_name,
        torch_dtype=torch.float16,
        device_map="auto",
        trust_remote_code=True
    )
    
    # é…ç½®LoRA
    peft_config = LoraConfig(
        task_type=TaskType.CAUSAL_LM,
        inference_mode=False,
        r=8,
        lora_alpha=32,
        lora_dropout=0.1,
        target_modules=["q_proj", "v_proj", "k_proj", "o_proj"]
    )
    
    model = get_peft_model(model, peft_config)
    model.print_trainable_parameters()
    
    # åŠ è½½å’Œé¢„å¤„ç†æ•°æ®
    print("ğŸ“Š åŠ è½½è®­ç»ƒæ•°æ®...")
    dataset = load_dataset(dataset_path)
    tokenized_dataset = dataset.map(
        lambda x: tokenize_function(x, tokenizer),
        batched=True,
        remove_columns=dataset.column_names
    )
    
    # è®­ç»ƒå‚æ•°
    training_args = TrainingArguments(
        output_dir=output_dir,
        num_train_epochs=3,
        per_device_train_batch_size=4,
        gradient_accumulation_steps=4,
        warmup_steps=100,
        learning_rate=2e-5,
        fp16=True,
        logging_steps=10,
        save_steps=100,
        eval_steps=100,
        save_total_limit=3,
        remove_unused_columns=False,
        push_to_hub=False,
        report_to="tensorboard",
    )
    
    # æ•°æ®æ•´ç†å™¨
    data_collator = DataCollatorForSeq2Seq(
        tokenizer=tokenizer,
        model=model,
        padding=True,
        return_tensors="pt"
    )
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=tokenized_dataset,
        data_collator=data_collator,
    )
    
    # å¼€å§‹è®­ç»ƒ
    print("ğŸš€ å¼€å§‹SFTè®­ç»ƒ...")
    trainer.train()
    
    # ä¿å­˜æ¨¡å‹
    print("ğŸ’¾ ä¿å­˜æ¨¡å‹...")
    trainer.save_model()
    tokenizer.save_pretrained(output_dir)
    
    print("âœ… è®­ç»ƒå®Œæˆ!")
    print(f"ğŸ“ æ¨¡å‹ä¿å­˜åœ¨: {output_dir}")

if __name__ == "__main__":
    main()
'''
    
    with open('train_sft.py', 'w', encoding='utf-8') as f:
        f.write(python_script)
    
    print("âœ… Pythonè®­ç»ƒè„šæœ¬å·²ç”Ÿæˆ: train_sft.py")

# 6. ç”Ÿæˆrequirements.txt
def generate_requirements():
    """ç”Ÿæˆä¾èµ–æ–‡ä»¶"""
    requirements = """
torch>=2.0.0
transformers>=4.35.0
datasets>=2.14.0
peft>=0.6.0
accelerate>=0.24.0
bitsandbytes>=0.41.0
tensorboard
scipy
scikit-learn
deepspeed
flash-attn>=2.3.0
"""
    
    with open('requirements.txt', 'w') as f:
        f.write(requirements.strip())
    
    print("âœ… ä¾èµ–æ–‡ä»¶å·²ç”Ÿæˆ: requirements.txt")

# 7. ç”ŸæˆLLaMA-Factoryé…ç½®
def generate_llamafactory_config():
    """ç”ŸæˆLLaMA-Factoryè®­ç»ƒé…ç½®"""
    
    # æ•°æ®é›†é…ç½®
    dataset_config = {
        "intimate_dataset": {
            "file_name": "intimate_sft_dataset.json",
            "formatting": "sharegpt",
            "columns": {
                "messages": "conversations"
            }
        }
    }
    
    with open('dataset_info.json', 'w', encoding='utf-8') as f:
        json.dump(dataset_config, f, indent=2, ensure_ascii=False)
    
    # è®­ç»ƒé…ç½®
    train_config = """
### model
model_name: llama2_7b_chat
model_revision: main

### method
stage: sft
do_train: true
finetuning_type: lora
lora_target: q_proj,v_proj
lora_rank: 8
lora_alpha: 32
lora_dropout: 0.1

### dataset
dataset: intimate_dataset
template: llama2
cutoff_len: 512
max_samples: 1000
overwrite_cache: true
preprocessing_num_workers: 16

### output
output_dir: ./saves/intimate-llama2-chat-lora
logging_steps: 10
save_steps: 500
plot_loss: true
overwrite_output_dir: true

### train
per_device_train_batch_size: 2
gradient_accumulation_steps: 4
learning_rate: 5.0e-5
num_train_epochs: 3.0
lr_scheduler_type: cosine
warmup_steps: 0.1
bf16: true
ddp_timeout: 180000000

### eval
val_size: 0.1
per_device_eval_batch_size: 1
evaluation_strategy: steps
eval_steps: 500
"""
    
    with open('intimate_sft_config.yaml', 'w') as f:
        f.write(train_config)
    
    print("âœ… LLaMA-Factoryé…ç½®å·²ç”Ÿæˆ:")
    print("   - dataset_info.json")
    print("   - intimate_sft_config.yaml")

# 8. ä¸»å‡½æ•° - æ‰§è¡Œæ‰€æœ‰å‡†å¤‡å·¥ä½œ
def main():
    """æ‰§è¡ŒSFTè®­ç»ƒå‡†å¤‡"""
    print("ğŸ”§ å‡†å¤‡SFTè®­ç»ƒç¯å¢ƒ...")
    print("=" * 50)
    
    # ä¿å­˜è®­ç»ƒæ•°æ®
    dataset_file = save_training_data()
    
    # ç”Ÿæˆè®­ç»ƒè„šæœ¬
    generate_training_script()
    generate_python_training_script()
    
    # ç”Ÿæˆé…ç½®æ–‡ä»¶
    generate_requirements()
    generate_llamafactory_config()
    
    print("\n" + "=" * 50)
    print("âœ… SFTè®­ç»ƒå‡†å¤‡å®Œæˆ!")
    print("\nğŸ“‹ ç”Ÿæˆçš„æ–‡ä»¶:")
    print("   ğŸ“„ intimate_sft_dataset.json - è®­ç»ƒæ•°æ® (1000æ¡)")
    print("   ğŸš train_intimate_sft.sh - Bashè®­ç»ƒè„šæœ¬")
    print("   ğŸ train_sft.py - Pythonè®­ç»ƒè„šæœ¬")
    print("   ğŸ“¦ requirements.txt - ä¾èµ–æ–‡ä»¶")
    print("   âš™ï¸  intimate_sft_config.yaml - LLaMA-Factoryé…ç½®")
    print("   ğŸ“Š dataset_info.json - æ•°æ®é›†ä¿¡æ¯")
    
    print("\nğŸš€ å¼€å§‹è®­ç»ƒ:")
    print("   æ–¹æ³•1 (æ¨è): llamafactory-cli train intimate_sft_config.yaml")
    print("   æ–¹æ³•2: bash train_intimate_sft.sh")
    print("   æ–¹æ³•3: python train_sft.py")
    
    print("\nğŸ’¡ è®­ç»ƒå»ºè®®:")
    print("   - å»ºè®®ä½¿ç”¨GPUè¿›è¡Œè®­ç»ƒ (è‡³å°‘8GBæ˜¾å­˜)")
    print("   - ä½¿ç”¨LoRAå¯ä»¥å‡å°‘æ˜¾å­˜éœ€æ±‚")
    print("   - å¯ä»¥è°ƒæ•´batch_sizeå’Œlearning_rateä¼˜åŒ–æ•ˆæœ")
    print("   - è®­ç»ƒè¿‡ç¨‹ä¸­ç›‘æ§losså˜åŒ–")
    
    print("\nğŸ” ç›‘æ§è®­ç»ƒ:")
    print("   tensorboard --logdir ./intimate-model-sft/runs")

if __name__ == "__main__":
    main()
