# SFTè®­ç»ƒç³»ç»Ÿ - é‡æ„ç‰ˆ

ä¸€ä¸ªæ¨¡å—åŒ–ã€æ˜“é…ç½®çš„SFT (Supervised Fine-Tuning) è®­ç»ƒç³»ç»Ÿï¼Œæ”¯æŒå¤šç§æ¨¡å‹å’Œæ•°æ®é›†çš„çµæ´»ç»„åˆã€‚

## ğŸ—ï¸ é¡¹ç›®ç»“æ„

```
enbodyIntellegence/
â”œâ”€â”€ config.py              # ğŸ”§ ç»Ÿä¸€é…ç½®æ–‡ä»¶
â”œâ”€â”€ data_manager.py         # ğŸ“Š æ•°æ®ç®¡ç†æ¨¡å—
â”œâ”€â”€ trainer.py             # ğŸš€ è®­ç»ƒæ¨¡å—
â”œâ”€â”€ evaluation.py          # ğŸ“ˆ è¯„ä¼°æ¨¡å—
â”œâ”€â”€ run_training.py        # ğŸ¯ ä¸»è®­ç»ƒè„šæœ¬
â”œâ”€â”€ SFT/                   # ğŸ“‚ è®­ç»ƒæ•°æ®æº
â”‚   â”œâ”€â”€ sft_adult_doll_eng.py          # è‹±æ–‡æˆäººå¯¹è¯
â”‚   â”œâ”€â”€ sft_adult_doll_shy_chn.py      # ä¸­æ–‡å®³ç¾å¯¹è¯
â”‚   â”œâ”€â”€ sft_adult_doll_having_sex.py   # ç”·æ€§ä¸»å¯¼å¯¹è¯
â”‚   â””â”€â”€ sft_adult_doll_before_sex_chn.py # äº‹å‰å¯¹è¯
â”œâ”€â”€ data/                  # ğŸ“ ç”Ÿæˆçš„æ•°æ®é›†
â”œâ”€â”€ models/                # ğŸ¤– è®­ç»ƒè¾“å‡ºçš„æ¨¡å‹
â”œâ”€â”€ logs/                  # ğŸ“‹ è®­ç»ƒæ—¥å¿—
â””â”€â”€ evaluation/            # ğŸ“Š è¯„ä¼°ç»“æœ
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–
```bash
pip install torch transformers datasets peft accelerate bitsandbytes tensorboard
```

### 2. æŸ¥çœ‹å¯ç”¨é…ç½®
```bash
python run_training.py config    # æŸ¥çœ‹å½“å‰é…ç½®
python run_training.py datasets  # æŸ¥çœ‹å¯ç”¨æ•°æ®é›†
python run_training.py demo      # æŸ¥çœ‹é…ç½®ç¤ºä¾‹
```

### 3. å¼€å§‹è®­ç»ƒ
```bash
python run_training.py           # ä½¿ç”¨é»˜è®¤é…ç½®è®­ç»ƒ
```

## ğŸ”§ é…ç½®ç³»ç»Ÿ

### æ¨¡å‹é…ç½® (config.py)

**1. å¿«é€Ÿåˆ‡æ¢æ¨¡å‹**
```python
from config import quick_config

# ä½¿ç”¨Qwen2.5-14Bæ¨¡å‹
quick_config(model_key="qwen_14b")

# ä½¿ç”¨Llama3-8Bæ¨¡å‹  
quick_config(model_key="llama3_8b")

# ä½¿ç”¨Phi-3-14Bæ¨¡å‹
quick_config(model_key="phi3_14b")
```

**2. å¯ç”¨æ¨¡å‹åˆ—è¡¨**
```python
qwen_72b    # Qwen/Qwen2.5-72B-Instruct      (72Bå‚æ•°)
qwen_14b    # Qwen/Qwen2.5-14B-Instruct      (14Bå‚æ•°)
qwen_7b     # Qwen/Qwen2.5-7B-Instruct       (7Bå‚æ•°)
phi3_14b    # microsoft/Phi-3-medium-4k-instruct
gemma_27b   # google/gemma-2-27b-it
mixtral_8x7b # mistralai/Mixtral-8x7B-Instruct-v0.1
llama3_8b   # meta-llama/Meta-Llama-3-8B-Instruct
llama3_70b  # meta-llama/Meta-Llama-3-70B-Instruct
```

**3. è‡ªå®šä¹‰æ¨¡å‹**
```python
from config import config

config.model.model_name = "your/custom-model"
config.model.lora_r = 16
config.model.lora_alpha = 64
```

### æ•°æ®é…ç½®

**1. å¿«é€Ÿåˆ‡æ¢æ•°æ®é›†**
```python
# ä½¿ç”¨å•ä¸ªæ•°æ®é›†
quick_config(datasets=["chinese_shy"])

# ä½¿ç”¨å¤šä¸ªæ•°æ®é›†
quick_config(datasets=["english_adult", "chinese_shy", "male_dominant"])
```

**2. å¯ç”¨æ•°æ®é›†**
```python
english_adult    # è‹±æ–‡æˆäººå¯¹è¯ (1000æ¡)
chinese_shy      # ä¸­æ–‡å®³ç¾å¯¹è¯ (1000æ¡)  
male_dominant    # ç”·æ€§ä¸»å¯¼å¯¹è¯ (1000æ¡)
before_sex       # äº‹å‰å¯¹è¯ (å¼€å‘ä¸­)
```

## ğŸ¯ ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹1: å¿«é€Ÿæµ‹è¯• (å°æ¨¡å‹)
```python
from trainer import quick_train

# ä½¿ç”¨7Bæ¨¡å‹å¿«é€Ÿæµ‹è¯•
model_path = quick_train(
    model_key="qwen_7b",
    datasets=["chinese_shy"],
    num_train_epochs=1,
    per_device_train_batch_size=2
)
```

### ç¤ºä¾‹2: ç”Ÿäº§è®­ç»ƒ (å¤§æ¨¡å‹)
```python
from trainer import quick_train

# ä½¿ç”¨72Bæ¨¡å‹å®Œæ•´è®­ç»ƒ
model_path = quick_train(
    model_key="qwen_72b", 
    datasets=["english_adult", "chinese_shy", "male_dominant"],
    num_train_epochs=3,
    learning_rate=5e-5
)
```

### ç¤ºä¾‹3: è‡ªå®šä¹‰é…ç½®è®­ç»ƒ
```python
from trainer import train_with_config

config_updates = {
    "model": {
        "model_name": "microsoft/Phi-3-medium-4k-instruct",
        "lora_r": 32,
        "load_in_4bit": True
    },
    "training": {
        "num_train_epochs": 5,
        "learning_rate": 1e-4,
        "per_device_train_batch_size": 1
    },
    "data": {
        "active_datasets": ["chinese_shy", "male_dominant"],
        "max_length": 1024
    }
}

model_path = train_with_config(config_updates)
```

## ğŸ“Š æ•°æ®ç®¡ç†

### åˆ›å»ºè‡ªå®šä¹‰æ•°æ®é›†
```python
from data_manager import create_dataset

# åˆ›å»ºç»„åˆæ•°æ®é›†
dataset_path = create_dataset(
    datasets=["english_adult", "chinese_shy"],
    format_type="sharegpt"  # sharegpt, alpaca, chat
)
```

### æ•°æ®æ ¼å¼æ”¯æŒ
- **ShareGPTæ ¼å¼**: å¯¹è¯æ ¼å¼ï¼Œé€‚åˆèŠå¤©æ¨¡å‹
- **Alpacaæ ¼å¼**: æŒ‡ä»¤æ ¼å¼ï¼Œé€‚åˆæŒ‡ä»¤è·Ÿéš
- **Chatæ ¼å¼**: ç®€å•é—®ç­”æ ¼å¼

## ğŸ“ˆ æ¨¡å‹è¯„ä¼°

```python
from evaluation import evaluate_model

# è¯„ä¼°è®­ç»ƒåçš„æ¨¡å‹
results = evaluate_model("./models/sft_output")
print(results)
```

## ğŸ’¡ æœ€ä½³å®è·µ

### ç¡¬ä»¶é…ç½®å»ºè®®

**å°æ¨¡å‹ (7B-14B)**
- GPU: 16GB+ (å•å¡)
- å†…å­˜: 32GB+
- å­˜å‚¨: 50GB+

**å¤§æ¨¡å‹ (27B-72B)**  
- GPU: 40GB+ (å¤šå¡æ›´ä½³)
- å†…å­˜: 64GB+
- å­˜å‚¨: 200GB+

### è®­ç»ƒå‚æ•°è°ƒä¼˜

**å¿«é€Ÿæµ‹è¯•**
```python
num_train_epochs=1
per_device_train_batch_size=1
gradient_accumulation_steps=8
learning_rate=5e-5
```

**ç”Ÿäº§è®­ç»ƒ**
```python
num_train_epochs=3
per_device_train_batch_size=4  
gradient_accumulation_steps=4
learning_rate=2e-5
```

## ğŸ” ç›‘æ§è®­ç»ƒ

```bash
# å¯åŠ¨TensorBoard
tensorboard --logdir ./models/sft_output/runs --port 6006

# è®¿é—® http://localhost:6006
```

## ğŸ› ï¸ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

**1. æ¨¡å‹ä¸‹è½½å¤±è´¥**
```python
# è§£å†³æ–¹æ¡ˆ: ä½¿ç”¨é•œåƒæˆ–æœ¬åœ°æ¨¡å‹
config.model.model_name = "æœ¬åœ°æ¨¡å‹è·¯å¾„"
```

**2. æ˜¾å­˜ä¸è¶³**
```python
# è§£å†³æ–¹æ¡ˆ: å¯ç”¨é‡åŒ–
config.model.load_in_8bit = True
config.training.per_device_train_batch_size = 1
config.training.gradient_accumulation_steps = 16
```

**3. æ•°æ®åŠ è½½å¤±è´¥**
```python
# è§£å†³æ–¹æ¡ˆ: æ£€æŸ¥æ•°æ®è·¯å¾„
python run_training.py datasets
```

## ğŸ“ æ›´æ–°æ—¥å¿—

### v2.0 (é‡æ„ç‰ˆ)
- âœ… æ¨¡å—åŒ–è®¾è®¡
- âœ… ç»Ÿä¸€é…ç½®ç³»ç»Ÿ
- âœ… çµæ´»æ•°æ®ç®¡ç†
- âœ… ç®€åŒ–ä½¿ç”¨æ¥å£
- âœ… æ”¯æŒå¤šç§æ¨¡å‹
- âœ… æ”¯æŒå¤šç§æ•°æ®æ ¼å¼

### v1.0 (åŸç‰ˆ)
- âœ… åŸºç¡€SFTè®­ç»ƒåŠŸèƒ½
- âœ… LoRAå¾®è°ƒæ”¯æŒ 

# SFT è®­ç»ƒé¡¹ç›® - å¢å¼ºæ—¥å¿—ç³»ç»Ÿ

è¿™æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç›‘ç£å¾®è°ƒ(SFT)è®­ç»ƒé¡¹ç›®ï¼Œå…·æœ‰å®Œå–„çš„æ—¥å¿—ç³»ç»Ÿï¼Œå¯ä»¥æ¸…æ¥šåœ°è¿½è¸ªè®­ç»ƒè¿‡ç¨‹çš„æ¯ä¸ªé˜¶æ®µï¼Œå¹¶åœ¨å‡ºé”™æ—¶æä¾›è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯ã€‚

## ğŸ¯ é¡¹ç›®ç‰¹æ€§

### ğŸš€ æ ¸å¿ƒåŠŸèƒ½
- **å¤šæ¨¡å‹æ”¯æŒ**: æ”¯æŒ Qwenã€LLaMAã€Phi-3ã€Gemma ç­‰ä¸»æµæ¨¡å‹
- **LoRA å¾®è°ƒ**: é«˜æ•ˆçš„å‚æ•°å¾®è°ƒæŠ€æœ¯
- **å¤šæ•°æ®é›†ç®¡ç†**: çµæ´»çš„æ•°æ®é›†é…ç½®å’Œç®¡ç†
- **å®Œæ•´è®­ç»ƒæµç¨‹**: ä»æ•°æ®åŠ è½½åˆ°æ¨¡å‹è¯„ä¼°çš„å®Œæ•´è‡ªåŠ¨åŒ–æµç¨‹

### ğŸ“Š å¢å¼ºæ—¥å¿—ç³»ç»Ÿ

#### ğŸ”§ æ—¥å¿—é…ç½®ç‰¹æ€§
- **å¤šçº§åˆ«æ—¥å¿—**: DEBUGã€INFOã€WARNINGã€ERRORã€CRITICAL
- **åŒé‡è¾“å‡º**: åŒæ—¶æ”¯æŒæ§åˆ¶å°å’Œæ–‡ä»¶è¾“å‡º
- **è‡ªåŠ¨æ–‡ä»¶ç®¡ç†**: è‡ªåŠ¨åˆ›å»ºæ—¥å¿—ç›®å½•å’Œæ–‡ä»¶
- **æ—¶é—´æˆ³è®°å½•**: ç²¾ç¡®åˆ°ç§’çš„æ—¶é—´è¿½è¸ª
- **emoji æ ‡è¯†**: ç›´è§‚çš„è§†è§‰æ ‡è¯†ï¼Œä¾¿äºå¿«é€Ÿå®šä½ä¿¡æ¯ç±»å‹

#### ğŸ“ˆ é˜¶æ®µæ€§è¿›åº¦è¿½è¸ª
- **æ­¥éª¤ç¼–å·**: æ¸…æ™°çš„ "æ­¥éª¤ X/Y" æ ¼å¼
- **è¿›åº¦ç™¾åˆ†æ¯”**: å®æ—¶è¿›åº¦æ˜¾ç¤º
- **é˜¶æ®µæè¿°**: è¯¦ç»†çš„æ“ä½œæè¿°
- **å®ŒæˆçŠ¶æ€**: æ˜ç¡®çš„å®Œæˆæ ‡è¯†

#### âŒ é”™è¯¯å¤„ç†å’Œè¯Šæ–­
- **å®Œæ•´å †æ ˆè·Ÿè¸ª**: è¯¦ç»†çš„é”™è¯¯å †æ ˆä¿¡æ¯
- **é”™è¯¯åˆ†ç±»**: æŒ‰é”™è¯¯ç±»å‹åˆ†ç±»è®°å½•
- **æ¢å¤å»ºè®®**: é’ˆå¯¹å¸¸è§é”™è¯¯çš„è§£å†³å»ºè®®
- **ä¸Šä¸‹æ–‡ä¿ç•™**: é”™è¯¯å‘ç”Ÿæ—¶çš„ç¯å¢ƒä¿¡æ¯

#### âš¡ æ€§èƒ½ç›‘æ§
- **æ“ä½œè€—æ—¶**: æ¯ä¸ªæ“ä½œçš„ç²¾ç¡®è€—æ—¶
- **æ€§èƒ½è­¦å‘Š**: è€—æ—¶è¾ƒé•¿æ“ä½œçš„è‡ªåŠ¨è­¦å‘Š
- **æ€»æ—¶é—´ç»Ÿè®¡**: å®Œæ•´æµç¨‹çš„æ—¶é—´ç»Ÿè®¡
- **æ•ˆç‡åˆ†æ**: æ€§èƒ½ç“¶é¢ˆè¯†åˆ«

## ğŸ“‹ ä½¿ç”¨æ–¹æ³•

### ğŸš€ å¿«é€Ÿå¼€å§‹

1. **æ¼”ç¤ºæ¨¡å¼** - æŸ¥çœ‹å½“å‰é…ç½®å’Œå¯ç”¨æ•°æ®é›†:
```bash
python run_training.py --mode demo
```

2. **å¿«é€Ÿè®­ç»ƒ** - ä½¿ç”¨é»˜è®¤é…ç½®è¿›è¡Œè®­ç»ƒ:
```bash
python run_training.py --mode quick --model qwen_7b --datasets english_adult
```

3. **è‡ªå®šä¹‰è®­ç»ƒ** - è‡ªå®šä¹‰è®­ç»ƒå‚æ•°:
```bash
python run_training.py --mode custom --epochs 5 --batch-size 8 --learning-rate 1e-5
```

### ğŸ“Š æ•°æ®ç®¡ç†

4. **åˆ—å‡ºå¯ç”¨æ•°æ®é›†**:
```bash
python run_training.py --mode list-data
```

5. **æ•°æ®åŠ è½½æµ‹è¯•**:
```bash
python -c "from data_manager import DataManager; from config import config; dm = DataManager(config.data); dm.load_datasets()"
```

### ğŸ¯ æ¨¡å‹è¯„ä¼°

6. **è¯„ä¼°å·²è®­ç»ƒæ¨¡å‹**:
```bash
python run_training.py --mode evaluate --model-path ./models/sft_output
```

### ğŸ§ª æ—¥å¿—åŠŸèƒ½æµ‹è¯•

7. **å®Œæ•´æ—¥å¿—åŠŸèƒ½æµ‹è¯•**:
```bash
python test_logging.py
```

## ğŸ“ é¡¹ç›®ç»“æ„

```
enbodyIntellegence/
â”œâ”€â”€ config.py              # ç»Ÿä¸€é…ç½®ç®¡ç†
â”œâ”€â”€ data_manager.py         # æ•°æ®åŠ è½½å’Œå¤„ç†
â”œâ”€â”€ trainer.py              # è®­ç»ƒå™¨å®ç°
â”œâ”€â”€ evaluation.py           # æ¨¡å‹è¯„ä¼°
â”œâ”€â”€ run_training.py         # ä¸»è®­ç»ƒè„šæœ¬
â”œâ”€â”€ test_logging.py         # æ—¥å¿—åŠŸèƒ½æµ‹è¯•
â”œâ”€â”€ logs/                   # æ—¥å¿—æ–‡ä»¶ç›®å½•
â”‚   â”œâ”€â”€ training.log        # ä¸»è®­ç»ƒæ—¥å¿—
â”‚   â””â”€â”€ enhanced_test.log   # æµ‹è¯•æ—¥å¿—
â”œâ”€â”€ SFT/                    # è®­ç»ƒæ•°æ®ç›®å½•
â”‚   â”œâ”€â”€ sft_adult_doll_eng.py
â”‚   â”œâ”€â”€ sft_adult_doll_shy_chn.py
â”‚   â””â”€â”€ ...
â”œâ”€â”€ models/                 # æ¨¡å‹è¾“å‡ºç›®å½•
â””â”€â”€ data/                   # æ•°æ®æ–‡ä»¶ç›®å½•
```

## ğŸ¨ æ—¥å¿—è¾“å‡ºç¤ºä¾‹

### ğŸ“Š é˜¶æ®µæ€§è¿›åº¦è¿½è¸ª
```
2025-06-25 21:55:04 - root - INFO - ğŸ”§ æ­¥éª¤ 1/6: ç¯å¢ƒæ£€æŸ¥
2025-06-25 21:55:04 - root - DEBUG - ğŸ” æ£€æŸ¥CUDAå¯ç”¨æ€§...
2025-06-25 21:55:04 - root - INFO - âœ… ç¯å¢ƒæ£€æŸ¥å®Œæˆ
2025-06-25 21:55:04 - root - INFO - ğŸ“Š æ­¥éª¤ 2/6: æ•°æ®å‡†å¤‡
2025-06-25 21:55:04 - root - INFO - ğŸ”„ åŠ è½½è®­ç»ƒæ•°æ®...
2025-06-25 21:55:04 - root - INFO - âœ… æ•°æ®å‡†å¤‡å®Œæˆ: 1000 æ¡è®­ç»ƒæ ·æœ¬
```

### âŒ é”™è¯¯å¤„ç†
```
2025-06-25 21:54:59 - root - ERROR - âŒ æ–‡ä»¶è¯»å–å¤±è´¥: [Errno 2] No such file or directory: 'non_existent_file.txt'
Traceback (most recent call last):
  File "test_logging.py", line 100, in test_error_handling
    with open("non_existent_file.txt", "r") as f:
FileNotFoundError: [Errno 2] No such file or directory: 'non_existent_file.txt'
```

### âš¡ æ€§èƒ½ç›‘æ§
```
2025-06-25 21:55:00 - root - INFO - ğŸ”„ å¼€å§‹æ‰§è¡Œ: æ¨¡å‹åˆå§‹åŒ–
2025-06-25 21:55:00 - root - INFO - âœ… æ¨¡å‹åˆå§‹åŒ– å®Œæˆ
2025-06-25 21:55:00 - root - INFO - â±ï¸  è€—æ—¶: 1.00ç§’
2025-06-25 21:55:00 - root - WARNING - âš ï¸  æ¨¡å‹åˆå§‹åŒ– æ‰§è¡Œæ—¶é—´è¾ƒé•¿: 1.00ç§’
```

### ğŸ“ˆ æ•°æ®åŠ è½½è¯¦æƒ…
```
2025-06-25 21:55:03 - data_manager - INFO - ğŸ”„ å¼€å§‹åŠ è½½æ•°æ®æ¨¡å—: sft_adult_doll_eng.py
2025-06-25 21:55:03 - data_manager - DEBUG - ğŸ“‚ è¯»å–æ–‡ä»¶: /path/to/sft_adult_doll_eng.py
2025-06-25 21:55:03 - data_manager - DEBUG - âœ… æ‰¾åˆ°æ•°æ®å˜é‡: sft_training_data
2025-06-25 21:55:03 - data_manager - INFO - âœ… æˆåŠŸåŠ è½½ 1000 æ¡æ•°æ®è®°å½•
2025-06-25 21:55:03 - data_manager - INFO - âœ… æ•°æ®æ ¼å¼éªŒè¯é€šè¿‡: english_adult
```

## âš™ï¸ é…ç½®è¯´æ˜

### ğŸ”§ æ—¥å¿—é…ç½®
```python
# åœ¨ config.py ä¸­é…ç½®æ—¥å¿—
@dataclass
class LoggingConfig:
    log_level: str = "INFO"                    # æ—¥å¿—çº§åˆ«
    log_file: Optional[str] = "logs/training.log"  # æ—¥å¿—æ–‡ä»¶è·¯å¾„
    console_output: bool = True                # æ§åˆ¶å°è¾“å‡º
    file_output: bool = True                   # æ–‡ä»¶è¾“å‡º
```

### ğŸ¤– æ¨¡å‹é…ç½®
- æ”¯æŒå¤šç§é¢„è®­ç»ƒæ¨¡å‹
- è‡ªåŠ¨é…ç½® LoRA å‚æ•°
- çµæ´»çš„é‡åŒ–é€‰é¡¹

### ğŸ“Š æ•°æ®é…ç½®
- å¤šæ•°æ®é›†æ”¯æŒ
- è‡ªåŠ¨æ ¼å¼éªŒè¯
- ç»Ÿè®¡ä¿¡æ¯ç”Ÿæˆ

### ğŸ¯ è®­ç»ƒé…ç½®
- å®Œæ•´çš„è®­ç»ƒå‚æ•°æ§åˆ¶
- è‡ªåŠ¨ä¿å­˜å’Œæ¢å¤
- è¯¦ç»†çš„è®­ç»ƒè®°å½•

## ğŸ” æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **transformers æœªå®‰è£…**:
```bash
pip install torch transformers datasets peft
```

2. **æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨**:
æ£€æŸ¥ `SFT/` ç›®å½•ä¸­çš„æ•°æ®æ–‡ä»¶ï¼Œç¡®ä¿æ–‡ä»¶è·¯å¾„æ­£ç¡®ã€‚

3. **å†…å­˜ä¸è¶³**:
è°ƒæ•´ `batch_size` æˆ–å¯ç”¨ `load_in_8bit` é‡åŒ–ã€‚

4. **æ—¥å¿—æ–‡ä»¶æ— æ³•åˆ›å»º**:
ç¡®ä¿æœ‰è¶³å¤Ÿçš„ç£ç›˜ç©ºé—´å’Œå†™å…¥æƒé™ã€‚

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–å»ºè®®

1. **ä½¿ç”¨é‡åŒ–**: å¯ç”¨ 8-bit æˆ– 4-bit é‡åŒ–èŠ‚çœå†…å­˜
2. **è°ƒæ•´æ‰¹æ¬¡å¤§å°**: æ ¹æ®GPUå†…å­˜è°ƒæ•´ `batch_size`
3. **æ¢¯åº¦ç´¯ç§¯**: ä½¿ç”¨ `gradient_accumulation_steps` æ¨¡æ‹Ÿå¤§æ‰¹æ¬¡
4. **æ··åˆç²¾åº¦**: å¯ç”¨ `bf16` æˆ– `fp16` åŠ é€Ÿè®­ç»ƒ

## ğŸ‰ åŠŸèƒ½äº®ç‚¹

### âœ¨ ç”¨æˆ·å‹å¥½
- æ¸…æ™°çš„emojiæ ‡è¯†ç³»ç»Ÿ
- ç›´è§‚çš„è¿›åº¦æ˜¾ç¤º
- è¯¦ç»†çš„çŠ¶æ€åé¦ˆ

### ğŸ”§ å¼€å‘å‹å¥½
- å®Œæ•´çš„é”™è¯¯å †æ ˆè·Ÿè¸ª
- è¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯
- æ¨¡å—åŒ–çš„è®¾è®¡

### ğŸ“Š ç›‘æ§å‹å¥½
- å®æ—¶æ€§èƒ½ç›‘æ§
- è¯¦ç»†çš„ç»Ÿè®¡ä¿¡æ¯
- è‡ªåŠ¨åŒ–çš„æŠ¥å‘Šç”Ÿæˆ

## ğŸ“ æ”¯æŒ

å¦‚æœåœ¨ä½¿ç”¨è¿‡ç¨‹ä¸­é‡åˆ°é—®é¢˜ï¼Œè¯·æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶ä¸­çš„è¯¦ç»†é”™è¯¯ä¿¡æ¯ï¼Œå¤§å¤šæ•°é—®é¢˜éƒ½æœ‰ç›¸åº”çš„è§£å†³å»ºè®®ã€‚

---

ğŸ¯ **ç›®æ ‡**: è®©æ¯ä¸€æ¬¡è®­ç»ƒéƒ½æœ‰è¿¹å¯å¾ªï¼Œè®©æ¯ä¸€ä¸ªé”™è¯¯éƒ½æœ‰è§£å¯ä¾ï¼ 