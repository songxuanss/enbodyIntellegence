# æ¨¡å‹é…ç½®å¢å¼º - è§£å†³æ­»æ¿é—®é¢˜

## ğŸ¯ é—®é¢˜è¯†åˆ«

æ‚¨æå‡ºçš„é—®é¢˜éå¸¸å‡†ç¡®ï¼åŸæ¥çš„æ¨¡å‹é…ç½®ç¡®å®è¿‡äºæ­»æ¿ï¼š
- âŒ åªèƒ½é€šè¿‡é¢„å®šä¹‰çš„keyæ¥é€‰æ‹©æ¨¡å‹
- âŒ æ— æ³•ä½¿ç”¨æ–°çš„æˆ–è‡ªå®šä¹‰æ¨¡å‹
- âŒ ä¸æ”¯æŒæœ¬åœ°æ¨¡å‹è·¯å¾„
- âŒ é™åˆ¶äº†ç”¨æˆ·çš„çµæ´»æ€§

## âœ… è§£å†³æ–¹æ¡ˆ

ç°åœ¨æˆ‘ä»¬å®ç°äº†**ä¸‰ç§çµæ´»çš„æ¨¡å‹é…ç½®æ–¹å¼**ï¼š

### 1. ğŸš€ å¿«æ·æ–¹å¼ï¼ˆä¾¿äºå¿«é€Ÿåˆ‡æ¢ï¼‰
```bash
# ä½¿ç”¨é¢„å®šä¹‰çš„å¿«æ·æ–¹å¼
python run_training.py --model qwen_7b
python run_training.py --model llama3_8b
python run_training.py --model phi3_4b
```

### 2. ğŸŒ å®Œæ•´HuggingFaceæ¨¡å‹åç§°ï¼ˆæ”¯æŒä»»æ„æ¨¡å‹ï¼‰
```bash
# ä½¿ç”¨ä»»ä½•HuggingFaceä¸Šçš„æ¨¡å‹
python run_training.py --model Qwen/Qwen2.5-3B-Instruct
python run_training.py --model microsoft/Phi-3-mini-4k-instruct
python run_training.py --model username/custom-model-name
```

### 3. ğŸ“ æœ¬åœ°æ¨¡å‹è·¯å¾„ï¼ˆæ”¯æŒæœ¬åœ°æ¨¡å‹ï¼‰
```bash
# ä½¿ç”¨æœ¬åœ°è®­ç»ƒæˆ–ä¸‹è½½çš„æ¨¡å‹
python run_training.py --model /path/to/local/model
python run_training.py --model ./fine-tuned-model
```

## ğŸ”§ æŠ€æœ¯å®ç°

### å¢å¼ºçš„ModelConfigç±»
```python
@dataclass
class ModelConfig:
    """æ¨¡å‹é…ç½® - æ”¯æŒçµæ´»çš„æ¨¡å‹åç§°é…ç½®"""
    # å¯ä»¥æ˜¯ä»»ä½•HuggingFaceæ¨¡å‹åç§°æˆ–æœ¬åœ°è·¯å¾„
    model_name: str = "Qwen/Qwen2.5-72B-Instruct"
    
    # å¸¸ç”¨æ¨¡å‹å¿«æ·æ–¹å¼ï¼ˆå¯é€‰ï¼‰
    model_shortcuts = {
        "qwen_7b": "Qwen/Qwen2.5-7B-Instruct",
        "qwen_3b": "Qwen/Qwen2.5-3B-Instruct",
        "phi3_4b": "microsoft/Phi-3-mini-4k-instruct",
        # ... æ›´å¤šå¿«æ·æ–¹å¼
    }
```

### æ™ºèƒ½æ¨¡å‹æ›´æ–°å‡½æ•°
```python
def update_model(self, model_identifier: str):
    """æ›´æ–°æ¨¡å‹ - æ”¯æŒå¿«æ·æ–¹å¼ã€å®Œæ•´æ¨¡å‹åç§°æˆ–æœ¬åœ°è·¯å¾„"""
    if model_identifier in self.model.model_shortcuts:
        # ä½¿ç”¨å¿«æ·æ–¹å¼
        self.model.model_name = self.model.model_shortcuts[model_identifier]
        print(f"âœ… æ¨¡å‹å·²åˆ‡æ¢ä¸º: {self.model.model_name} (å¿«æ·æ–¹å¼: {model_identifier})")
    else:
        # ç›´æ¥ä½¿ç”¨å®Œæ•´çš„æ¨¡å‹åç§°æˆ–æœ¬åœ°è·¯å¾„
        self.model.model_name = model_identifier
        print(f"âœ… æ¨¡å‹å·²è®¾ç½®ä¸º: {self.model.model_name}")
    
    # è‡ªåŠ¨é‡æ–°é…ç½®LoRAå‚æ•°
    self.model.__post_init__()
```

### æ¨¡å‹éªŒè¯å’Œå»ºè®®ç³»ç»Ÿ
```python
def validate_model_identifier(model_identifier: str) -> dict:
    """éªŒè¯å¹¶åˆ†ææ¨¡å‹æ ‡è¯†ç¬¦"""
    # æ£€æŸ¥å¿«æ·æ–¹å¼ã€æœ¬åœ°è·¯å¾„ã€HuggingFaceæ ¼å¼
    # è¿”å›è¯¦ç»†çš„éªŒè¯ç»“æœ
    
def get_model_suggestions(partial_name: str) -> List[str]:
    """æ ¹æ®éƒ¨åˆ†åç§°è·å–æ¨¡å‹å»ºè®®"""
    # æä¾›æ™ºèƒ½å»ºè®®
```

## ğŸ“Š å¯ç”¨çš„æ¨¡å‹å¿«æ·æ–¹å¼

### Qwenç³»åˆ—
- `qwen_0.5b` â†’ Qwen/Qwen2.5-0.5B-Instruct
- `qwen_1.5b` â†’ Qwen/Qwen2.5-1.5B-Instruct
- `qwen_3b` â†’ Qwen/Qwen2.5-3B-Instruct
- `qwen_7b` â†’ Qwen/Qwen2.5-7B-Instruct
- `qwen_14b` â†’ Qwen/Qwen2.5-14B-Instruct
- `qwen_72b` â†’ Qwen/Qwen2.5-72B-Instruct

### LLaMAç³»åˆ—
- `llama3_8b` â†’ meta-llama/Meta-Llama-3-8B-Instruct
- `llama3_70b` â†’ meta-llama/Meta-Llama-3-70B-Instruct
- `llama3.1_8b` â†’ meta-llama/Meta-Llama-3.1-8B-Instruct
- `llama3.1_70b` â†’ meta-llama/Meta-Llama-3.1-70B-Instruct
- `llama3.2_1b` â†’ meta-llama/Llama-3.2-1B-Instruct
- `llama3.2_3b` â†’ meta-llama/Llama-3.2-3B-Instruct

### Phiç³»åˆ—
- `phi3_4b` â†’ microsoft/Phi-3-mini-4k-instruct
- `phi3_14b` â†’ microsoft/Phi-3-medium-4k-instruct

### Gemmaç³»åˆ—
- `gemma_2b` â†’ google/gemma-2-2b-it
- `gemma_9b` â†’ google/gemma-2-9b-it
- `gemma_27b` â†’ google/gemma-2-27b-it

### å…¶ä»–æ¨¡å‹
- `yi_9b` â†’ 01-ai/Yi-1.5-9B-Chat
- `yi_34b` â†’ 01-ai/Yi-1.5-34B-Chat
- `deepseek_7b` â†’ deepseek-ai/deepseek-coder-7b-instruct-v1.5
- `deepseek_33b` â†’ deepseek-ai/deepseek-coder-33b-instruct
- `chatglm_6b` â†’ THUDM/chatglm3-6b
- `baichuan_7b` â†’ baichuan-inc/Baichuan2-7B-Chat
- `baichuan_13b` â†’ baichuan-inc/Baichuan2-13B-Chat
- `mixtral_8x7b` â†’ mistralai/Mixtral-8x7B-Instruct-v0.1

## ğŸ¯ å®é™…ä½¿ç”¨ç¤ºä¾‹

### å¿«é€Ÿåˆ‡æ¢å¸¸ç”¨æ¨¡å‹
```bash
# ä»å¤§æ¨¡å‹åˆ‡æ¢åˆ°å°æ¨¡å‹è¿›è¡Œå¿«é€Ÿæµ‹è¯•
python run_training.py --mode quick --model qwen_3b --datasets english_adult

# ä½¿ç”¨LLaMAæ¨¡å‹
python run_training.py --mode custom --model llama3.2_3b --epochs 2
```

### ä½¿ç”¨æœ€æ–°å‘å¸ƒçš„æ¨¡å‹
```bash
# ç›´æ¥ä½¿ç”¨HuggingFaceä¸Šä»»ä½•æ–°å‘å¸ƒçš„æ¨¡å‹
python run_training.py --model organization/new-model-name
```

### ä½¿ç”¨è‡ªå·±å¾®è°ƒçš„æ¨¡å‹
```bash
# ä½¿ç”¨ä¹‹å‰è®­ç»ƒä¿å­˜çš„æ¨¡å‹ç»§ç»­è®­ç»ƒ
python run_training.py --model ./models/my-fine-tuned-model
```

## ğŸ› ï¸ éªŒè¯å’Œé”™è¯¯æç¤º

### æ™ºèƒ½éªŒè¯
```bash
# è¾“å…¥é”™è¯¯çš„æ¨¡å‹åæ—¶ä¼šå¾—åˆ°å»ºè®®
$ python run_training.py --model qwen
âŒ æ— æ•ˆçš„æ¨¡å‹æ ‡è¯†ç¬¦: qwen
ğŸ’¡ ç›¸ä¼¼çš„å¿«æ·æ–¹å¼: qwen_0.5b, qwen_1.5b, qwen_14b
```

### è‡ªåŠ¨LoRAé…ç½®
ç³»ç»Ÿä¼šæ ¹æ®æ¨¡å‹ç±»å‹è‡ªåŠ¨é…ç½®åˆé€‚çš„LoRA target_modulesï¼š
- **Qwenæ¨¡å‹**: `["q_proj", "v_proj", "k_proj", "o_proj", "gate_proj", "up_proj", "down_proj"]`
- **LLaMAæ¨¡å‹**: `["q_proj", "v_proj", "k_proj", "o_proj", "gate_proj", "up_proj", "down_proj"]`
- **Phiæ¨¡å‹**: `["qkv_proj", "o_proj", "gate_up_proj", "down_proj"]`
- **Gemmaæ¨¡å‹**: `["q_proj", "v_proj", "k_proj", "o_proj", "gate_proj", "up_proj", "down_proj"]`

## ğŸ‰ ä¼˜åŠ¿æ€»ç»“

### âœ… è§£å†³äº†æ­»æ¿é—®é¢˜
1. **å®Œå…¨å‘åå…¼å®¹** - åŸæœ‰çš„å¿«æ·æ–¹å¼ä¾ç„¶æœ‰æ•ˆ
2. **æ— é™æ‰©å±•æ€§** - æ”¯æŒä»»ä½•HuggingFaceæ¨¡å‹
3. **æœ¬åœ°æ¨¡å‹æ”¯æŒ** - å¯ä»¥ä½¿ç”¨æœ¬åœ°è·¯å¾„
4. **æ™ºèƒ½æç¤º** - è¾“å…¥é”™è¯¯æ—¶æä¾›å»ºè®®
5. **è‡ªåŠ¨é…ç½®** - æ ¹æ®æ¨¡å‹ç±»å‹è‡ªåŠ¨è®¾ç½®LoRAå‚æ•°

### ğŸš€ æå‡ç”¨æˆ·ä½“éªŒ
- **æ–°æ‰‹å‹å¥½**: å¯ä»¥ä½¿ç”¨ç®€å•çš„å¿«æ·æ–¹å¼
- **ä¸“å®¶çµæ´»**: å¯ä»¥ä½¿ç”¨ä»»ä½•æ¨¡å‹å’Œè·¯å¾„
- **é”™è¯¯æ¢å¤**: æ™ºèƒ½å»ºè®®å’Œé”™è¯¯æç¤º
- **æ— ç¼é›†æˆ**: ä¸ç°æœ‰è®­ç»ƒæµç¨‹å®Œç¾å…¼å®¹

### ğŸ“ˆ å®é™…æ”¶ç›Š
- ä¸å†å—é™äºé¢„å®šä¹‰çš„æ¨¡å‹åˆ—è¡¨
- å¯ä»¥ç«‹å³ä½¿ç”¨æ–°å‘å¸ƒçš„æ¨¡å‹
- æ”¯æŒä½¿ç”¨è‡ªå·±è®­ç»ƒçš„æ¨¡å‹
- æé«˜äº†å¼€å‘å’Œå®éªŒæ•ˆç‡

---

**æ€»ç»“**: ç°åœ¨çš„æ¨¡å‹é…ç½®ç³»ç»Ÿæ—¢ä¿æŒäº†å¿«æ·æ–¹å¼çš„ä¾¿åˆ©æ€§ï¼Œåˆæä¾›äº†å®Œå…¨çš„çµæ´»æ€§ï¼Œå®Œç¾è§£å†³äº†ä¹‹å‰"å¤ªæ­»æ¿"çš„é—®é¢˜ï¼ğŸ¯ 